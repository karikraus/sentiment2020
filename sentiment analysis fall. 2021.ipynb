{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob and Vader for Sentiment Analysis\n",
    "\n",
    "To get started with this notebook, you'll need to install several Python packages: TextBlob, Pandas, Matplotlib, and NLTK. Here are instructions:\n",
    "\n",
    "**EASIEST METHOD**: \n",
    "Textblob: in a new code cell, type and execute the following:  \n",
    "\n",
    "import sys  \n",
    "!{sys.executable} -m pip install -U textblob  \n",
    "!{sys.executable} python -m textblob.download_corpora  \n",
    "\n",
    "If that doesn't work, try:  \n",
    "import sys  \n",
    "!{sys.executable} -m pip install -U textblob  \n",
    "python -m textblob.download_corpora  \n",
    "\n",
    "If neither of those work, you'll want to try installing from your terminal or console window:\n",
    "1. For both Mac and Windows operating systems, you'll want to open a console or terminal window. The relevant application on Mac machines is \"Terminal.\"\n",
    "2. Point your browser to the TextBlob documentation page and follow the instructions for your operating system:  \n",
    "https://textblob.readthedocs.io/en/dev/install.html\n",
    "3. Note that when typing in the relevant commands, you should omit the \"$\" sign\n",
    "\n",
    "**Pandas**: in the same JUPYTER NOTEBOOK, type and execute in a single cell:  \n",
    "import sys  \n",
    "!{sys.executable} -m pip install pandas\n",
    "\n",
    "If that doesn't work, follow instructions above for installing from your Terminal or Console window using this code:  \n",
    "import sys  \n",
    "-m pip install pandas\n",
    "\n",
    "**Matplotlib**: In the same JUPYTER NOTEBOOK, type and execute in a single cell:  \n",
    "import sys  \n",
    "!{sys.executable} pip install matplotlib  \n",
    "\n",
    "If that doesn't work, open terminal window and type, then carriage return:  \n",
    "pip install matplotlib\n",
    "\n",
    "OR  \n",
    "conda install matplotlib\n",
    "\n",
    "**NLTK**: from same JUPYTER NOTEBOOK, type and execute the following in a new cell:  \n",
    "import sys  \n",
    "!{sys.executable} pip install --user -U nltk\n",
    "\n",
    "In a new cell, type and execute:  \n",
    "import sys  \n",
    "!{sys.executable} pip install --user -U numpy  \n",
    "\n",
    "\n",
    "If those don't work, try installing from your Console or Terminal window:\n",
    "\n",
    "pip install --user -U nltk  \n",
    "pip install --user -U numpy  \n",
    "\n",
    "For more instructions on installing NLTK, point your browser here: \n",
    "https://www.nltk.org/install.html\n",
    "\n",
    "To run the code on *The Yellow Wallpaper* and \"To a Skull on my Bookshelf,\" upload the files to your Jupyter notebook environment. To obtain a copy of these texts, point your browser to Project Gutenberg and select the \"plain text UTF 8\" format: \n",
    "\n",
    "1. Charlotte Perkins Gilman's [_The Yellow Wallpaper_](https://www.gutenberg.org/ebooks/1952)\n",
    "2. [Virginia Raplee's \"To a Skull on my Bookshelf\"](https://www.gutenberg.org/cache/epub/32499/pg32499.txt)\n",
    "\n",
    "Once you've installed the requisite Python packages and placed your texts in the same directory as all your Jupyter notebooks, you're ready to start playing. If you're interacting directly with my online interactive notebook, you don't need to worry about any of the installations (either TextBlob Matplotlib, Pandas, NLTK, or the novels or poems). You can just start executing and typing code. If you get an automated message or prompt from the system to type in one or two additional lines of code for TextBlob to work in my online notebook, simply enter the relevant commands. \n",
    "\n",
    "Note: you can also upload your own texts to experiment with in my online Notebook if you're not working with your own Jupyter installation. You'll want to use the \"Upload\" button. I created resources for you in the \"Pages\" section of Elms if you have additional questions for how to do this.\n",
    "\n",
    "General resource: for information on installing python libraries directly from a Jupyter Notebook rather than a console window, see [here](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI: sometimes a particular cell doesn't generate any output once you run it (it's just preparatory code for further code in subsequent cells); other times, it may take a while for the output to appear. The square brackets to the left of each cell serve as a status indicator as to whether the code in that cell is still active and processing after you've executed it. If it's still processing, you'll see an asterisk appear between the brackets. That asterisk disappears and is replaced by a number once Jupyter notebook has generated output or otherwise completed its tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Sentiment Analysis?\n",
    "\n",
    "Sentiment analysis involves the use of algorithms to calculate the emotional content and intensity of different media, including text. In computational parlance, \"polarity\" refers to one of two labels--positive or negative--that can assigned to different media. Since we're dealing with literary media in this class, we'll be calculating the polarity of novels, poems, and stories at different levels of analysis: words, sentences, and entire works. \n",
    "\n",
    "Let's import textblob, the first sentiment analyzer we'll be exploring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply textblob's sentiment analyzer to words, sentences, and larger units. To calculate the sentiment, we need to blobify the text by writing \"TextBlob\" ahead of the word, sentence, or passage, contained between quotation marks and embedded in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('laughed').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that textblob assigns not only a polarity value to an expression, but also a subjectivity value. We'll look at both in detail below.  \n",
    "\n",
    "We can assign a polarity value for a particular expression to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = TextBlob('A house of deadly chambers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('A house of deadly chambers').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('inhabited by evil spirits').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('lit by gruesome torches').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('The Biltong was dying. Huge and old, it squatted in the center of the settlement park, a lump of ancient yellow protoplasm, thick, gummy, opaque. Its pseudopodia were dried up, shriveled to blackened snakes that lay inert on the brown grass.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(\"A pox on the pandemic!\").sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! That last calculation assigned a \"0\" polarity and subjectivity score to \"A pox on the pandemic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(\"Raindrops on roses and whiskers on kittens: these are a few of my favorite things.\").sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TextBlob documentation provides the following information about the sentiment scoring: \"The **polarity** score is a float within the range [-1.0, 1.0]. The **subjectivity** is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\" In terms of the polarity value that TextBlob returns for a given sentence, -1 is the most negative score and 1 is the most positive. Between them is a spectrum of possibilities, e.g., -.7 or .4 or 0 and so forth). \n",
    "\n",
    "Before you know how any given sentiment analyzer works, it can be surprisingly hard to compose sentences that garner an extremely negative or extremely positive score. Create some new code cells and try writing the happiest, sunniest, bubbliest, most cheerful and exuberant sentence you can to test. Then try writing the saddest, most heartbreaking, miserable, and wretched sentence you can (rant against COVID-19 if that helps; or if reality is too painful to address right now, transcribe a sentence from a favorite tearjerker of a novel or poem). Finally, try a Goldlilocks sentence that is right in the middle. See if through this method you can begin to get a feel for what the range of polarity scores mean. Do a similar exercise for testing subjectivity. You might try writing sentences with unicorns and mythological creatures versus empirical fact-based sentences. Again, the goal is to begin to internalize what the different numerical values mean.  After you've done that, we'll talk a little about how TextBlob is calculating sentiment.  \n",
    "\n",
    "Now that we've experimented with small units of text--individual words and sentences--let's calculate the sentiment for \"To a Skull on My Bookshelf\" (1936), a grisly poem by Virginia Raplee. It feels appropriate for the month of October as we approach Halloween.\n",
    "\n",
    "Open the poem, assigning it to the variable \"relic\", and print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relic = TextBlob(open(\"relic.txt\").read())\n",
    "print(relic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we added \"TextBlob\" in front of the familiar open statement in order to blobify it so that we can use TextBlob's sentiment capabilities.\n",
    "\n",
    "Calculate the sentiment for the poem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relic.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, the overall polarity is negative. Let's calculate the sentiment for a single line in the poem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('Your empty sockets, with sardonic gaze').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From poetry to novella: Open, read, and print a small portion of \"The Yellow Wallpaper\" (notice again our blobification of the novella):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_wallpaper = TextBlob(open(\"yellow_wallpaper2.txt\").read())\n",
    "print(yellow_wallpaper[0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_wallpaper.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line of code calculates the sentiment for the entire work. But we can get more granular than that. In the next block of code, let's use a \"for\" loop to iterate through every sentence in the novella. As we cycle through each one, we'll use an \"if\" statement to check to see if the sentence under consideration has a sentiment score of \"-1\"--an extreme negativity score. If it does, we'll print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    if item.sentiment.polarity == -1:\n",
    "        print(item)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four sentences that meet the extreme threshold we've specified. Let's modulate that \"-1\" value to \"-.4\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    if item.sentiment.polarity == -.4:\n",
    "        print(item)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test for extreme positivity, at least according to the sentiment analyzer. Note that we've changed the value we're checking for in our \"for\" loop to \"1\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    if item.sentiment.polarity == 1:\n",
    "        print(item)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Try\n",
    "Two of the polarity scores in the blocks of code, above, lie at the extremes of -1 most negative and +1 most positive. Try changing the number in the blocks to a float value between those scores. For instance, you might change \"-1\" to \"-.7\" or \"-.3\" to see what happens. Or \"1\" to \".7\" or \".2\" to see what you generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check for extreme subjectivity (as opposed to polarity). Study the \"if\" statement below to see how subjectivity is specified. Remember that subjectivity scores range from \"0\" (most objective) to \"1\" (most subjective). We'll be testing for maximum subjectivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    if item.sentiment.subjectivity == 1:\n",
    "        print(item)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test for extreme objectivity. Note the change in value, below, in the \"if\" statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    if item.sentiment.subjectivity == 0:\n",
    "        print(item)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Try\n",
    "The subjectivity values tested in the blocks of code, above, lie at the extremes of \"0\" (most factual) and \"1\" (most subjective). Note that this scale differs from the one for polarity. Try changing the numbers in each of the code blocks to a float value between those scores. For instance, you might change \"0\" to \".4\" or \".8\" to see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below might be of use as you begin to calculate sentiment for other texts. The block of code below iterates through every sentence in \"The Yellow Wallpaper\", prints its sentiment score and prints the sentence associated with that score. You can adapt this code by opening your own file for a different novel or poem, making sure to convert it to a TextBlob object, and assigning it to a variable. Then substitute your variable for your chosen work in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    print(item.sentiment.polarity)\n",
    "    print(item)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is a block of code called a \"function\". It basically bundles the code into a unit that can be reused and applied to any text. It takes a text and calculates what percentage of its sentences are negative. The name of the function is \"ratio\". Run the code below so that you can then call it on other texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(sequence):\n",
    "    total = 0\n",
    "    for item in sequence.sentences:\n",
    "        if item.sentiment.polarity < 0:\n",
    "            total = total +1\n",
    "    ratio = (float(total) / (len)(sequence.sentences)) * 100\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call the \"ratio\" function on a text, we write \"ratio\" in a code cell, followed by the variable name for the variable holding the text of your choice (being sure that text has been blobified--see previous code cells further up in this notebook for how to do that). For demo purposes, we're continuing to use \"The Yellow Wallpaper\" as our case study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio(yellow_wallpaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So rounding up, about 27 percent of the novel contains sentences that the sentiment analyzer has determined have a negative valence. Does that comport with your experience of reading the novella?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our first visualization. The first thing that happens in the block of code below is the assignment of an empty list to the variable \"wallpaper\" (those square brackets signify that we're going to be populating the empty list with list elements). We'll then iterate through every sentence in the novella, calculate its sentiment score, and append it to the list (recall that we learned how to append list elements in our \"Lists\" notebook a few weeks back). The final line of code prints every sentiment score that has now been added to the originally empty list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallpaper = []\n",
    "for item in yellow_wallpaper.sentences:\n",
    "    wallpaper.append(item.sentiment.polarity)\n",
    "print(wallpaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to import a bunch of libraries to create our visualization and stipulate some basic parameters for our figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_rows', 25)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take those sentiment values held in the \"wallpaper\" variable and convert them into what's called a \"Panda\" series for visualization. Pandas is a popular Python library for data manipulation. We'll learn more about Pandas in a week or two; for now I'll hold off on details. Note that we're assigning this converted list to the variable \"yellow\" (as always, be sure to run every cell in the notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = pd.Series(wallpaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to create our first visualization, a line graph. The line graph plots every sentiment value for every sentence in \"The Yellow Wallpaper\" on the graph, then connects them with lines. If you study the graph, you can see the rise and fall of sentiment values as the score for each consecutive sentence is plotted. The visualization allows you to see patterns in sentiment extremes across the entire work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group sentences whose sentiment values fall within certain ranges with the help of a histogram (abbreviated as \"hist\" in the code cell). Note how most sentences hover within and around the neutral to slightly positive range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one other new dimension to TextBlob's sentiment analyzer that I want to introduce you to before we move on to Vader, our second sentiment analyzer. First, run the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from collections import namedtuple\n",
    "\n",
    "import nltk\n",
    "\n",
    "from textblob.en import sentiment as pattern_sentiment\n",
    "from textblob.tokenizers import word_tokenize\n",
    "from textblob.decorators import requires_nltk_corpus\n",
    "from textblob.base import BaseSentimentAnalyzer, DISCRETE, CONTINUOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we'll run a block of code we've already seen, which identifies which sentences in the novella meet the maximum negative sentiment score of \"-1\", then prints those sentences  out. But there's one crucial difference: this time, using \"sentiment_assessments\", we've added new information that reveals what word or words in the sentence were used to caluclate the score (bearing in mind that not every word in a sentence is scored). This new information is displayed in list format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences:\n",
    "    if item.sentiment.polarity == -1:\n",
    "        print(item)\n",
    "        print(item.sentiment_assessments)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader for Sentiment Analysis\n",
    "Vader is an alternate sentiment analyzer that--like TextBlob's Pattern implementation--relies on a lexical approach. Since we're using NLTK instead of TextBlob, we won't be blobifying our texts. The syntax will look different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the code below will only work if you've installed the Python NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\"raindrops on roses and whiskers on kittens: these are a few of my favorite things\",\"A pox on the pandemic!\"]\n",
    "x = SIA()\n",
    "for sentence in sentences:\n",
    "    s = x.polarity_scores(sentence)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scoring system for Vader assumes that each sentence might potentially have an emotional valence that is a mix of positive and negative. The \"compound\" score at the end is Vader's attempt to reconcile those mixed affective states and combine them in a single score. It's that compound score that we'll mostly be working with.\n",
    "\n",
    "To split our texts into lines (for poetry) or sentences (for prose), we need to process our poems and novels a bit differently than we did with TextBlob. You might remember the splitlines() method from notebook on lists. Let's work again with Raplee's \"To a Skull on my Bookshelf\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relic2 = open('relic.txt').read()\n",
    "k = relic2.splitlines()\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below uses a \"for\" loop to cycle through every line in the poem. It then calculates the sentiment score and prints out both the line and the associated scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in k:\n",
    "    s = x.polarity_scores(line)\n",
    "    print(line)\n",
    "    print(s)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than calculating the scores for individual lines, we can also calculate a holistic score for the poem as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.polarity_scores(relic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the Vader sentiment analyzer with \"The Yellow Wallpaper\", first calculating a sentiment score for the entire novella:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_vader = open('yellow_wallpaper2.txt').read()\n",
    "t.polarity_scores(yellow_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course, also assign the score to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = t.polarity_scores(yellow_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're working with Vader and not TextBlob, we need an alternate means of splitting the novella into sentences. To do that, we'll use NLTK's sentence tokenizer and then apply it to \"The Yellow Wallpaper\". We'll assign our list of all the sentences to the variable \"text\" and print them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = sent_tokenize(yellow_vader)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cycle through every sentence and print out its \"compound\" sentiment score, as well as the full sentiment score that includes the positive and negative breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in text:\n",
    "    s = x.polarity_scores(sentence)\n",
    "    print(s['compound'])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print out each sentence that is less than \"-.9\" (since there are no sentences in the novella that achieve a maximum \"-1\" score as calculated by Vader). You should be able to parse what's happening in the code with the \"for\" and \"if\" loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in text:\n",
    "    s = x.polarity_scores(sentence)\n",
    "    if s['compound'] < -.9:\n",
    "        print(sentence)\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what sentiment value TextBlob assigns to the same sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(\"It is dull enough to confuse the eye in following, pronounced enough to constantly irritate, and provoke study, and when you follow the lame,uncertain curves for a little distance they suddenly commit suicide — plunge off at outrageous angles, destroy themselves in unheard-of contradictions.\").sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already done a line graph using scores we obtained from TextBlob; let's do the same for scores obtained from Vader. First we'll iterate through every sentence in the novella and assign its compound value to the \"wallpaper2\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallpaper2 = []\n",
    "for item in text:\n",
    "    ss = t.polarity_scores(item)\n",
    "    wallpaper2.append(ss['compound'])\n",
    "    print(item)\n",
    "    print(ss)\n",
    "    print('')\n",
    "print(wallpaper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert our list of sentences from \"The Yellow Wallpaper\" to a pandas series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow2 = pd.Series(wallpaper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we'll do the same for the TextBlob values, repeating the work we did earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = pd.Series(wallpaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the Vader values as both a line graph and a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow2.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the TextBlob and Vader values, let's plot them both on the same graph. The TextBlob values are in red, the Vader values in blue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow.plot()\n",
    "yellow2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences, while sometimes minimal, are at other times more pronounced. Let's take a closer look at just the first two sentences in the novella:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the Vader sentiment scores for just the first two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow2[0:2].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the TextBlob sentiment scores for just the first two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow[0:2].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both on the same graph, below (TextBlob scores in red, Vader scores in blue):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow[0:2].plot()\n",
    "yellow2[0:2].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again the TextBlob scores for those two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in yellow_wallpaper.sentences[0:2]:\n",
    "    print(item)\n",
    "    print(item.sentiment.polarity)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Vader scores for the same sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in text[0:2]:\n",
    "    ss = t.polarity_scores(item)\n",
    "    print(item)\n",
    "    print(ss['compound'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Sentiment Analysis Works\n",
    "Both TextBlob and Vader make use of lexical approaches to calculate sentiment: human raters have assigned positive or negative labels and/or numerical scores to a dictionary of words, and some additional contextual information--fairly minimal--is also factored in to each score (e.g., capitalization, punctuation, and various modifiers). \n",
    "\n",
    "Machine learning offers an alternative approach to sentiment analysis. A classifier is trained on a corpus, which involves a collection of already labeled texts dubbed a \"training set.\" Then new texts are fed to the classifier, which evaluates them and assigns scores based on what it's learned from the training set. \n",
    "\n",
    "If you want to pull back the curtain to better understand how TextBlob calculates sentiment, here's a great rundown: https://planspace.org/20150607-textblob_sentiment/\n",
    "\n",
    "More on [Vader](https://medium.com/@piocalderon/vader-sentiment-analysis-explained-f1c4f9101cd9)\n",
    "\n",
    "If you'd like to learn more about a method of sentiment analysis that is based on a supervised machine learning approach (rather than the lexical approach of TextBlob and Vader), check out the Naive Bayes classification method. Here's a good overview: https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Further Idea and Looking Ahead to the Exploratory Data Analysis\n",
    "\n",
    "Try authoring your own short poem, using a sentiment constraint: for example, a poem whose every line meets either a very high or very low polarity score (either negative or positive) or subjectivity score. \n",
    "\n",
    "For your exploratory data analysis assignment, you'll need to apply sentiment analysis to a novel or novella of your choice. I encourage you to select a text, get it into UTF-8 format, and practice running the code in this notebook on that text. A great source for public domains novels is [Project Gutenberg](https://www.gutenberg.org/). Every text is available in a variety of formats, including UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
